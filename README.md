# llm-quantization
how to optimize large language models (LLMs) to reduce memory usage and computational resource requirements, making them lighter and more efficient.
